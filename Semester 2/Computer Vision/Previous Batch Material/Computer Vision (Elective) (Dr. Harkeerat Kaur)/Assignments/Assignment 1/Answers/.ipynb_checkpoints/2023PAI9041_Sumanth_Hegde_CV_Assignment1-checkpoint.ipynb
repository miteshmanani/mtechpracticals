{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Vision Assignment 1\n",
    "# Sumanth Hegde\n",
    "# 2023PAI9041\n",
    "# Cohort 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Answer 1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import io\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def kmeans_quantization(image, k):\n",
    "    # Flatten the image array to make it compatible with KMeans\n",
    "    pixels = image.reshape((-1, 3))\n",
    "    \n",
    "    # Fit KMeans model\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(pixels)\n",
    "    \n",
    "    # Quantize the image\n",
    "    quantized_pixels = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    quantized_image = quantized_pixels.reshape(image.shape)\n",
    "    \n",
    "    return quantized_image\n",
    "\n",
    "def calculate_mse(original_image, quantized_image):\n",
    "    return mean_squared_error(original_image.flatten(), quantized_image.flatten())\n",
    "\n",
    "def main(image_path):\n",
    "    # Read the RGB image\n",
    "    original_image = io.imread(image_path)\n",
    "    \n",
    "    # Display original image\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Convert RGB image to quantized image for various k values\n",
    "    k_values = [1, 2, 4, 8, 16]\n",
    "    mse_values = []\n",
    "    quantized_images = []\n",
    "    for k in k_values:\n",
    "        quantized_image = kmeans_quantization(original_image, k)\n",
    "        quantized_images.append(quantized_image)\n",
    "        mse = calculate_mse(original_image, quantized_image)\n",
    "        mse_values.append(mse)\n",
    "    print ( mse_values)  \n",
    "    \n",
    "    # Display quantized images\n",
    "    for i, (k, quantized_image) in enumerate(zip(k_values, quantized_images), start=2):\n",
    "        plt.subplot(2, len(k_values), i)\n",
    "        plt.imshow(quantized_image.astype(np.uint8))\n",
    "        plt.title(f'k={k}\\nMSE={mse_values[i-2]:.2f}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Let us use the 2nd image \n",
    "image_path = 'F:\\RGB image 2.jpg'\n",
    "main(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f93b58",
   "metadata": {},
   "source": [
    "K-means clustering is a widely used method for image quantization, which involves reducing the number of colors in an image to a specified number of clusters (k).\n",
    "\n",
    "\n",
    "\n",
    "Our observation - \n",
    "\n",
    "From the above output of the code we can see that, as the value of k increases, MSE decreases - this suggests that we should go for a high value of k. But, if the value of k is too high, it may not provide the desired compression benefits. Therefore, selection of the optimal value of k is very important.\n",
    "Also, the overall values of MSE (for the above k values = 1,2,4,8,16) is in general, high. This suggests that we can go for other methods for image quantization (such as - Median Cut Algorithm, Octree Quantization, Uniform Quantization, Neural Networks Error Diffusion (Dithering) etc etc)\n",
    "\n",
    "\n",
    "\n",
    "Effectiveness of K-Means Image Quantization - \n",
    "\n",
    "1) Color Reduction Efficiency - K-means is highly effective at reducing the number of colors to a predefined number of k colors. This can dramatically decrease the image size while retaining the visual essence of the original image.\n",
    "2) Adaptability - K-means adapts to the specific color distribution of the image, ensuring that the selected colors (centroids of the clusters) are representative of the original image palette.\n",
    "3) MSE Reduction: In terms of MSE, k-means aims to minimize the within-cluster variances, which directly contributes to reducing the MSE between the original and the quantized image.\n",
    "\n",
    "\n",
    "Limitations of K-Means Image Quantization -\n",
    "\n",
    "1) Selection of K - Too small a value of k may lead to a high MSE due to oversimplification of the color palette, while too large a value may not provide the desired compression benefits. Finding the optimal k often requires domain knowledge or experimentation.\n",
    "2) Initial Centroid Sensitivity - K-means is sensitive to the initial placement of centroids. \n",
    "3) Local Minima - The algorithm may converge to a local minimum rather than the global minimum, which can cause a high MSE\n",
    "4) Computationally Intensive - For large images or high values of k, k-means can be computationally intensive due to the iterative nature of the algorithm. This can be a limitation in scenarios requiring real-time processing.\n",
    "5) Uniformity Assumption - K-means assumes uniform densities within clusters, which might not be ideal for all images."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cf484cf",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a811b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = \"F:\\connected component.jpg\"  \n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply binary thresholding to create a binary image\n",
    "_, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find connected components ---- we will use '8 connectivity'\n",
    "num_labels, labels_im, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8, ltype=cv2.CV_32S)\n",
    "\n",
    "# Create an output image to draw the labels\n",
    "output_image = np.zeros((original_image.shape), np.uint8)\n",
    "\n",
    "# Assign unique colors to components\n",
    "for label in range(0, num_labels):  \n",
    "    mask = labels_im == label\n",
    "    output_image[mask] = np.random.randint(0, 255, size=(3,))\n",
    "\n",
    "    # We can also draw component stats or centroids as below\n",
    "    # For example, to draw bounding boxes around components:\n",
    "    x, y, w, h, area = stats[label]\n",
    "    cv2.rectangle(output_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Show the original and output images\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Connected Components\", output_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4b6d21a",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35513be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lena_gray_512_path = \"F:\\lena_gray_512.tif\"\n",
    "lena_gray_256_path = \"F:\\lena_gray_256.tif\"\n",
    "\n",
    "# Load the original Lena image\n",
    "lena_gray_512 = cv2.imread(lena_gray_512_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Downsample the Lena image to 256x256\n",
    "reduce_lena_256 = cv2.resize(lena_gray_512, (256, 256))\n",
    "\n",
    "# Save the reduced image\n",
    "reduce_lena_256_path = \"F:\\reduce_lena_256.tif\"\n",
    "cv2.imwrite(reduce_lena_256_path, reduce_lena_256)\n",
    "\n",
    "# Load the reference image\n",
    "lena_gray_256 = cv2.imread(lena_gray_256_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images are loaded properly\n",
    "if lena_gray_256 is None or reduce_lena_256 is None:\n",
    "    print(\"Error: Unable to load images.\")\n",
    "else:\n",
    "    # Compute PSNR between the reduced and reference images\n",
    "    psnr = cv2.PSNR(lena_gray_256, reduce_lena_256)\n",
    "    print(\"PSNR between reduced_lena_256.tif and lena_gray_256.tif:\", psnr)\n",
    "\n",
    "    # Compute MSE between the reduced and reference images\n",
    "    mse = np.mean((lena_gray_256 - reduce_lena_256) ** 2)\n",
    "    print(\"Mean Squared Error (MSE) between the images:\", mse)\n",
    "\n",
    "    # Plot the difference between the images\n",
    "    plt.imshow(lena_gray_256 - reduce_lena_256, cmap='gray')\n",
    "    plt.title('MSE Difference between Images')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Resize the reduced image to original dimensions using different interpolation methods\n",
    "    nearest_neighbour = cv2.resize(reduce_lena_256, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    bilinear = cv2.resize(reduce_lena_256, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    bicubic = cv2.resize(reduce_lena_256, (512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Display the resized images\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    axs[0, 0].imshow(lena_gray_512, cmap='gray')\n",
    "    axs[0, 0].set_title('Original Image')\n",
    "\n",
    "    axs[0, 1].imshow(nearest_neighbour, cmap='gray')\n",
    "    axs[0, 1].set_title('Nearest Neighbour Interpolation')\n",
    "\n",
    "    axs[1, 0].imshow(bilinear, cmap='gray')\n",
    "    axs[1, 0].set_title('Bilinear Interpolation')\n",
    "\n",
    "    axs[1, 1].imshow(bicubic, cmap='gray')\n",
    "    axs[1, 1].set_title('Bicubic Interpolation')\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "404ae4d8",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05641490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def apply_filters(image_path):\n",
    "    # Read the noisy image\n",
    "    noisy_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if noisy_image is None:\n",
    "        print(\"Error: Could not read the image.\")\n",
    "        return\n",
    "\n",
    "   # Apply multiple noise reduction filters sequentially\n",
    "    filtered_image = cv2.GaussianBlur(noisy_image, (3, 3), 9)\n",
    "    filtered_image = cv2.medianBlur(filtered_image, 15)\n",
    "    filtered_image = cv2.bilateralFilter(filtered_image, 9, 50, 50)\n",
    "\n",
    "    # Apply unsharp masking for overall sharpness enhancement\n",
    "    unsharp_mask = cv2.addWeighted(filtered_image, 1.05, noisy_image, -0.10, 0)\n",
    "\n",
    "    # Apply histogram equalization for contrast enhancement\n",
    "    equalized_image = cv2.equalizeHist(unsharp_mask)\n",
    "\n",
    "    # Display input, filtered, sharpened, and equalized images side-by-side\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Input (noisy) image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(noisy_image, cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Filtered image\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(filtered_image, cmap='gray')\n",
    "    plt.title('Filtered Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Sharpened image (unsharp masking)\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(unsharp_mask, cmap='gray')\n",
    "    plt.title('Sharpened Image (Unsharp Masking)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Equalized image\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(equalized_image, cmap='gray')\n",
    "    plt.title('Equalized Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Specify the image path\n",
    "image_path = \"F:/Noisy image.jpg\"\n",
    "apply_filters(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8c28c",
   "metadata": {},
   "source": [
    "Let us see about each of the filters used in the above code - \n",
    "\n",
    "1. Gaussian Blur Filter - Reduces Gaussian noise and smooths out details in the image.\n",
    "\n",
    "2. Median Blur Filter - Removes salt-and-pepper noise, which appears as isolated bright and dark pixels in the image.\n",
    "\n",
    "3. Bilateral Filter - Preserves edges while reducing noise by applying a non-linear filter based on both spatial distance and                         intensity difference.\n",
    "\n",
    "4. Unsharp Masking - Enhances overall image sharpness by emphasizing edges and details.\n",
    "\n",
    "5. Histogram Equalization - Enhances the contrast of the image by redistributing pixel intensity values to cover the entire                                 dynamic range more evenly."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7c09337",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ae143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = \"F:\\lake.tif\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compute first order derivative along 'x'\n",
    "dx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "\n",
    "# Compute first order derivative along 'y'\n",
    "dy = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Compute gradient image magnitude\n",
    "gradient_magnitude = cv2.magnitude(dx, dy)\n",
    "\n",
    "# Thresholding to output edge map\n",
    "threshold_value = 50\n",
    "_, edge_map_first_order = cv2.threshold(gradient_magnitude, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Edge map computed using second order derivative\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "_, edge_map_second_order = cv2.threshold(np.uint8(np.absolute(laplacian)), threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Edge map using LoG (Laplacian of Gaussian)\n",
    "# Apply Gaussian blur\n",
    "image_blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "# Apply Laplacian\n",
    "log = cv2.Laplacian(image_blurred, cv2.CV_64F)\n",
    "_, edge_map_log = cv2.threshold(np.uint8(np.absolute(log)), threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Canny edge detector\n",
    "canny_edge = cv2.Canny(image, 100, 200)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(np.uint8(dx), cmap='gray')\n",
    "plt.title('First Order Derivative along x')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(np.uint8(dy), cmap='gray')\n",
    "plt.title('First Order Derivative along y')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(np.uint8(gradient_magnitude), cmap='gray')\n",
    "plt.title('Gradient Image Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(edge_map_first_order, cmap='gray')\n",
    "plt.title('Edge Map First Order')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(edge_map_second_order, cmap='gray')\n",
    "plt.title('Edge Map Second Order')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display additional edge maps\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(edge_map_log, cmap='gray')\n",
    "plt.title('Edge Map LoG')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(canny_edge, cmap='gray')\n",
    "plt.title('Canny Edge Detector')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cecd82d7",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67323b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6 \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the image data\n",
    "image_data = np.array([\n",
    "    [167, 144, 159],\n",
    "    [140, 135, 154],\n",
    "    [135, 148, 148]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Get the image dimensions\n",
    "height, width = image_data.shape\n",
    "\n",
    "# Create an empty list to store the bit planes\n",
    "bit_planes = []\n",
    "\n",
    "# Loop through each bit plane (from MSB to LSB)\n",
    "for i in range(8):\n",
    "    # Create an empty bit plane\n",
    "    bit_plane = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Extract the current bit from each pixel and set the corresponding bit in the bit plane\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            # Extract the current bit using bitwise AND operation with 2^i (left shift i by 1)\n",
    "            bit_value = (image_data[y, x] >> i) & 1\n",
    "\n",
    "            # Set the corresponding bit in the bit plane\n",
    "            bit_plane[y, x] = bit_value * 255\n",
    "\n",
    "    # Append the bit plane to the list\n",
    "    bit_planes.append(bit_plane)\n",
    "\n",
    "# Print the bit planes\n",
    "for i, bit_plane in enumerate(bit_planes):\n",
    "    print(f\"Bit plane {i+1}:\")\n",
    "    print(bit_plane)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c3f66",
   "metadata": {},
   "source": [
    "This code performs bit-plane slicing, separating the image into its constituent bit planes, and prints each bit plane. Each bit plane represents the image's intensity at a particular bit depth.\n",
    "\n",
    "\n",
    "\n",
    "Let us understand the above code, step-by-step :\n",
    "\n",
    "1. Import NumPy: 'import numpy as np' imports the NumPy library under the alias 'np'. \n",
    "\n",
    "2. Define the image data: The image data is defined as a 3x3 NumPy array with pixel intensity values ranging from 0 to 255. Each pixel represents grayscale intensity, where 0 is black and 255 is white.\n",
    "\n",
    "3. Get the image dimensions: 'height, width = image_data.shape' retrieves the height and width of the image data array.\n",
    "\n",
    "4. Create an empty list to store the bit planes: 'bit_planes = []' initializes an empty list where the bit planes of the image will be stored.\n",
    "\n",
    "5. Loop through each bit plane (from MSB to LSB): A loop iterates from 0 to 7, representing the bit positions from Most Significant Bit (MSB) to Least Significant Bit (LSB).\n",
    "\n",
    "6. Create an empty bit plane: 'bit_plane = np.zeros((height, width), dtype=np.uint8)' creates an empty bit plane of the same size as the input image, initialized with zeros.\n",
    "\n",
    "7. Extract the current bit from each pixel and set the corresponding bit in the bit plane: Nested loops iterate over each pixel in the image.\n",
    "\n",
    "8. Extract the current bit: '(image_data[y, x] >> i) & 1' shifts the pixel intensity value 'image_data[y, x]' by 'i' bits to the right and performs a bitwise AND operation with 1. This extracts the ith bit from the pixel intensity value.\n",
    "\n",
    "9. Set the corresponding bit in the bit plane: The extracted bit value is multiplied by 255 to set it to either 0 or 255 (representing black or white) and assigned to the corresponding location in the bit plane.\n",
    "\n",
    "10. Append the bit plane to the list: 'bit_planes.append(bit_plane)' adds the generated bit plane to the list of bit planes.\n",
    "\n",
    "11. Print the bit planes: The code iterates over the generated bit planes and prints them one by one, along with their corresponding bit plane index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
