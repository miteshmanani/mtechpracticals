{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6cdab5f4",
   "metadata": {},
   "source": [
    "Sumanth Hegde\n",
    "2023PAI9041\n",
    "Computer Vision Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b40498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_fundamental_matrix(points1, points2):\n",
    "    # Compute the fundamental matrix using RANSAC\n",
    "    F, mask = cv2.findFundamentalMat(points1, points2, cv2.FM_RANSAC)\n",
    "    return F\n",
    "\n",
    "def draw_epipolar_lines(img1, img2, points1, points2, F):\n",
    "    # Find epilines corresponding to points in the second image (lines in the first image)\n",
    "    lines1 = cv2.computeCorrespondEpilines(points2.reshape(-1,1,2), 2, F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    img1 = draw_lines(img1, lines1, points1)\n",
    "\n",
    "    # Find epilines corresponding to points in the first image (lines in the second image)\n",
    "    lines2 = cv2.computeCorrespondEpilines(points1.reshape(-1,1,2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    img2 = draw_lines(img2, lines2, points2)\n",
    "\n",
    "    return img1, img2\n",
    "\n",
    "def draw_lines(img, lines, pts):\n",
    "    r, c = img.shape[:2]\n",
    "    for r, pt in zip(lines, pts):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        img = cv2.line(img, (x0, y0), (x1, y1), color, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread('image1.jpg')\n",
    "img2 = cv2.imread('image2.jpg')\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# Create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# Sort them in the order of their distance\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "# Extract location of good matches\n",
    "points1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "points2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "# Reshape for findFundamentalMat\n",
    "points1 = points1.reshape(-1, 1, 2)\n",
    "points2 = points2.reshape(-1, 1, 2)\n",
    "\n",
    "# Compute the fundamental matrix\n",
    "F = find_fundamental_matrix(points1, points2)\n",
    "\n",
    "# Draw the epipolar lines\n",
    "img1_epilines, img2_epilines = draw_epipolar_lines(img1, img2, points1, points2, F)\n",
    "\n",
    "# Resize images to fit within the screen\n",
    "resized_img1 = cv2.resize(img1_epilines, (img1_epilines.shape[1] // 9, img1_epilines.shape[0] // 9))\n",
    "resized_img2 = cv2.resize(img2_epilines, (img2_epilines.shape[1] // 9, img2_epilines.shape[0] // 9))\n",
    "\n",
    "# Display resized images with epipolar lines\n",
    "cv2.imshow('Epilines in Image 1 (Resized)', resized_img1)\n",
    "cv2.imshow('Epilines in Image 2 (Resized)', resized_img2)\n",
    "\n",
    "# Wait for a key press and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4aca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Capture the video\n",
    "\n",
    "# Step 2: Extract frames from the video\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "frames = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "cap.release()\n",
    "\n",
    "# Step 3: Detect SIFT Features\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints = []\n",
    "keypoint_frames = []\n",
    "for frame in frames:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    kp, des = sift.detectAndCompute(gray, None)\n",
    "    keypoints.append(kp)\n",
    "    img = cv2.drawKeypoints(gray, kp, None)\n",
    "    keypoint_frames.append(img)\n",
    "\n",
    "# Step 4: Compute Optical Flow\n",
    "prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.KeyPoint_convert(keypoints[0])\n",
    "p0 = np.expand_dims(p0, axis=1).astype(np.float32)\n",
    "hsv_masks = []\n",
    "for frame in frames[1:]:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None)\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    # Create a mask image for drawing (to draw lines between the current and previous points)\n",
    "    mask = np.zeros_like(frame)\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "    img = cv2.add(frame, mask)\n",
    "    hsv_masks.append(img)\n",
    "    # Update the previous frame and previous points\n",
    "    prev_gray = gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "# Step 5: Overlay Flow on a Black Background\n",
    "output_frames = []\n",
    "for mask in hsv_masks:\n",
    "    black_background = np.zeros_like(mask)\n",
    "    overlay = cv2.addWeighted(black_background, 1, mask, 1, 0)\n",
    "    output_frames.append(overlay)\n",
    "\n",
    "# Step 6: Compile the Output Frames into a Video\n",
    "out = cv2.VideoWriter('optical_flow_dance.avi', cv2.VideoWriter_fourcc(*'DIVX'), 15, (frames[0].shape[1], frames[0].shape[0]))\n",
    "for frame in output_frames:\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
