{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates the different loading and saving methods of ANN perceptron model"
      ],
      "metadata": {
        "id": "lWvv3EwetRwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAstXs2qqAQJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ANDPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANDPerceptron, self).__init__()\n",
        "        self.fc = nn.Linear(2, 1)  # Input size: 2, Output size: 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "T1nJXwKasqL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the AND perceptron model\n",
        "model = ANDPerceptron()"
      ],
      "metadata": {
        "id": "oDv4zG7SstCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input data (truth table for AND operation)\n",
        "inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "EHwfcBs9stnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the expected outputs\n",
        "expected_outputs = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "VWbBMi0Pswgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "bh5v-_-Jsxah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model to learn the AND operation\n",
        "for epoch in range(1000):\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, expected_outputs)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-mb7vLUs2LB",
        "outputId": "e1c5c57c-20f6-46f5-fce9-1cc042e9ec48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.1742\n",
            "Epoch [200/1000], Loss: 0.1433\n",
            "Epoch [300/1000], Loss: 0.1214\n",
            "Epoch [400/1000], Loss: 0.1054\n",
            "Epoch [500/1000], Loss: 0.0933\n",
            "Epoch [600/1000], Loss: 0.0836\n",
            "Epoch [700/1000], Loss: 0.0758\n",
            "Epoch [800/1000], Loss: 0.0692\n",
            "Epoch [900/1000], Loss: 0.0636\n",
            "Epoch [1000/1000], Loss: 0.0588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model\n",
        "torch.save(model, 'and_perceptron_entire.pth')"
      ],
      "metadata": {
        "id": "msYmIfP2s40S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only the model weights\n",
        "torch.save(model.state_dict(), 'and_perceptron_weights.pth')"
      ],
      "metadata": {
        "id": "MYys1dBas7ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire model\n",
        "loaded_model_entire = torch.load('and_perceptron_entire.pth')"
      ],
      "metadata": {
        "id": "p_V2PiSSs9d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model weights\n",
        "loaded_model_weights = ANDPerceptron()\n",
        "loaded_model_weights.load_state_dict(torch.load('and_perceptron_weights.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og4DDb28s_1j",
        "outputId": "1d8bb6e1-e6e4-4250-a653-719dc5da4324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the loaded models are in evaluation mode\n",
        "loaded_model_entire.eval()\n",
        "loaded_model_weights.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIvJ6_VCtCHg",
        "outputId": "2ee6c393-5e45-45f3-b9aa-13408c3e2338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ANDPerceptron(\n",
              "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the loaded models\n",
        "test_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "with torch.no_grad():\n",
        "    for input in test_inputs:\n",
        "        output_entire = loaded_model_entire(input)\n",
        "        output_weights = loaded_model_weights(input)\n",
        "        print(f'Input: {input.tolist()}, Output (Entire Model): {output_entire.item():.4f}, Output (Weights Only): {output_weights.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WeNhH-wtEYu",
        "outputId": "85ec790f-ff5d-48eb-92ab-90939a6f0f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0.0, 0.0], Output (Entire Model): 0.0523, Output (Weights Only): 0.0523\n",
            "Input: [0.0, 1.0], Output (Entire Model): 0.2541, Output (Weights Only): 0.2541\n",
            "Input: [1.0, 0.0], Output (Entire Model): 0.2564, Output (Weights Only): 0.2564\n",
            "Input: [1.0, 1.0], Output (Entire Model): 0.6805, Output (Weights Only): 0.6805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pD5YadzjtHeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}